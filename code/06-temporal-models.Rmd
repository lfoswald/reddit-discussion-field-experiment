---
title: "Temporal Models"
subtitle: "Reddit Communities Field Experiment"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, out.width = "100%", out.height = "30%", message=F, warning=F)
```

```{r}
library(tidyverse)
library(lubridate)
library(lme4)
library(survival)
library(survminer)
library(gridExtra)
library(ggpubr)
library(ggeffects)
```

Load anonymous data (no comment texts, open comments, usernames or email addresses)
```{r , results='hide'}
# reddit data
discussion_data <- read_csv("../data/anon/discussions_anon.csv")
sample <- read_csv("../data/anon/sample_anon.csv")
# preprocessed survey data
scaled_sample <- read_csv("../data/anon/scaled_sample.csv")
```


# Social Feedback 

### Construct lagged dataframe
```{r, results='hide'}
#arrange by day
daily_discussion_data <- discussion_data %>% arrange(created_comment) %>% mutate(day = as.Date(created_comment)) %>% group_by(ParticipantID, day) %>% dplyr::summarize(n_comments = n(), mean_score = mean(score_comment), mean_toxicity = mean(comment_toxicity, na.rm=T), sum_score = sum(score_comment, na.rm=T))

# Pad out the daily_discussion_data dataframe to have a row for each ParticipantID-day combination
daily_discussion_data_complete <- daily_discussion_data %>% ungroup %>% complete(ParticipantID, day)
daily_discussion_data_complete$n_comments[which(is.na(daily_discussion_data_complete$n_comments))] <- 0

# Construct lagged data structure
# Note: This loop is inefficient, but has the virtue of making explicit exactly how the lagged mean score is calculated

lagged_data <- daily_discussion_data_complete
pb <- txtProgressBar(min = 0, max = nrow(lagged_data), style = 3)
for (i in 1:nrow(lagged_data)) {
  setTxtProgressBar(pb, i)
  if (lagged_data$day[i] <= (lagged_data %>% filter(ParticipantID == lagged_data$ParticipantID[i]) %>% filter(n_comments!=0) %>% pull(day) %>% min)){
    lagged_data$mean_score_lag[i] <- NA
  } else {
    lags <- lagged_data %>% filter(ParticipantID == lagged_data$ParticipantID[i] & day < lagged_data$day[i]) %>% dplyr::summarize(mean_score = mean(mean_score, na.rm = T), sum_score = sum(sum_score, na.rm = T))
    lagged_data$mean_score_lag[i] <- lags %>% pull(mean_score)
  }
}

#augment with survey data
lagged_data <- left_join(lagged_data, sample, by = "ParticipantID") %>% 
  mutate(condition = as.factor(condition))

```

### Estimate Social Feedback Models
```{r}
#basic model
model <- glmer(n_comments ~ mean_score_lag + (1 | ParticipantID), 
               data = lagged_data, 
               family = poisson(link = "log"),
               na.action = na.exclude)

summary(model)
```

```{r}
# More elaborate model
model <- glmer(n_comments ~ mean_score_lag + polinterest + (1 | ParticipantID) + (1 | subreddit), 
               data = lagged_data, 
               family = poisson(link = "log"),
               na.action = na.exclude)
summary(model)

```
### Visualization of social feedback effect
```{r}
coef_est <- fixef(model)["mean_score_lag"]
se_est <- summary(model)$coefficients["mean_score_lag", "Std. Error"]
lower_ci <- coef_est - 1.96 * se_est
upper_ci <- coef_est + 1.96 * se_est

coef_label <- paste0(" = ", round(coef_est, 2),
                     " [", round(lower_ci, 2), ", ", round(upper_ci, 2), "]")

# predicted values across the range of mean_score_lag
predictions <- ggpredict(model, terms = c("mean_score_lag [all]", "polinterest [mean]"),
                         bias_correction = TRUE)

feedback_plot <- ggplot(predictions, aes(x = x, y = predicted)) +
  geom_line(color = "black", size = 1) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2, fill = "black") +
  annotate("text",x = 0, y = 4, size = 4, hjust = 0,
           label = bquote(beta == .(round(coef_est, 2)) ~ "[" ~ .(round(lower_ci, 2)) ~ "," ~ .(round(upper_ci, 2)) ~ "]")) +
  labs(x = "Mean score received on previous comments (lagged)",
       y = "Predicted Number of Comments",
       title = "Social Feedback") +
  theme_bw()

feedback_plot

ggsave("../output/social_feedback.pdf", feedback_plot, width = 4, height = 2.5)

```


# Modeling Drop-out with Survival Models
```{r}
# observation period's end (e.g., 30 days after start)
end_of_observation <- as.Date(min(discussion_data$created_comment)) + 30

# Prepare the survival data
survival_data <- discussion_data %>%
  group_by(ParticipantID) %>%
  summarize(discussion_start = min(created_comment),
    last_comment_date = max(created_comment),
    time = as.numeric(pmin(last_comment_date, end_of_observation) - discussion_start),
    status = ifelse(last_comment_date <= end_of_observation, 1, 0))%>%
  left_join(.,scaled_sample,by = "ParticipantID")

# h(t) hazard's function: risk of dying at time t, given the covariates. Covariates > 0 increase in hazard, # covariates < 0 decrease in hazard / negative predictor for dropout.    
res.cox <- coxph(Surv(time,status) ~ condition + group_toxicity, data = survival_data) 
summary(res.cox)
```

## Kaplan-Meier survival curves for visualization
```{r}
# for different groups
surv_fit <- survfit(Surv(time, status) ~ condition, data = survival_data)

surv_group_plot <- ggsurvplot(surv_fit,
  data = survival_data,
  ggtheme = theme_bw(),
  surv.median.line = "hv",
  pval = TRUE,
  pval.size = 3,
  palette = c("grey","#29c195","#6699FF"), 
  conf.int = TRUE,  
  #risk.table = TRUE,
  #              tables.height = 0.2,
  #              tables.theme = theme_cleantable(),
  legend.title = "Experimental Condition", 
  legend.labs = c("Control", "Incentives", "Moderation"), 
  xlab = "Days of Discussion Phase",  
  xlim = c(1, 28) ,
  ylab = "Probability for Continued Participation")

surv_group_plot

ggexport(plotlist =list(surv_group_plot),filename = "../output/group_survival.pdf", width = 5, height = 4)
```


```{r}
# split along toxicity
toxicity_threshold <- quantile(survival_data$group_toxicity, 0.8, na.rm = TRUE)

survival_data <- survival_data %>%
  mutate(toxicity_group = ifelse(group_toxicity > toxicity_threshold, "High", "Low"))

surv_fit <- survfit(Surv(time, status) ~ toxicity_group, data = survival_data)

surv_tox_plot <- ggsurvplot(surv_fit,
  data = survival_data,
  ggtheme = theme_bw(),
  surv.median.line = "hv",
  pval = TRUE,
  pval.size = 3,
  palette = c("darkred","#6699FF"), 
  conf.int = TRUE,   
  legend.title = "Toxicity Group", # Customize legend title
  legend.labs = c("High Group Toxicity", "Low Group Toxicity"), 
  xlab = "Days of Discussion Phase",  
  xlim = c(1, 28) ,
  ylab = "Probability for Continued Participation")

surv_tox_plot

ggexport(plotlist = list(surv_tox_plot), filename = "../output/tox_survival.pdf", width = 5, height = 4)
```


