---
title: "Temporal Models"
subtitle: "Reddit Communities Field Experiment"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, out.width = "100%", out.height = "30%", message=F, warning=F)
```

```{r}
library(tidyverse)
library(lubridate)
library(lme4)
library(survival)
library(survminer)
library(gridExtra)
library(ggpubr)
library(ggeffects)
```

Load anonymous data (no comment texts, open comments, usernames or email addresses)
```{r , results='hide'}
# reddit data
discussion_data <- read_csv("../data/anon/discussions_anon.csv")
sample <- read_csv("../data/anon/sample_anon.csv")
# preprocessed survey data
scaled_sample <- read_csv("../data/anon/scaled_sample.csv")
```


# Social Feedback 

### Construct lagged dataframe
```{r, results='hide'}
#arrange by day
daily_discussion_data <- discussion_data %>% arrange(created_comment) %>% mutate(day = as.Date(created_comment)) %>% group_by(ParticipantID, day) %>% dplyr::summarize(n_comments = n(), mean_score = mean(score_comment), mean_toxicity = mean(comment_toxicity, na.rm=T), sum_score = sum(score_comment, na.rm=T))

# Pad out the daily_discussion_data dataframe to have a row for each ParticipantID-day combination
daily_discussion_data_complete <- daily_discussion_data %>% ungroup %>% complete(ParticipantID, day)
daily_discussion_data_complete$n_comments[which(is.na(daily_discussion_data_complete$n_comments))] <- 0

# Construct lagged data structure
# Note: This loop is inefficient, but has the virtue of making explicit exactly how the lagged mean score is calculated

lagged_data <- daily_discussion_data_complete
pb <- txtProgressBar(min = 0, max = nrow(lagged_data), style = 3)
for (i in 1:nrow(lagged_data)) {
  setTxtProgressBar(pb, i)
  if (lagged_data$day[i] <= (lagged_data %>% filter(ParticipantID == lagged_data$ParticipantID[i]) %>% filter(n_comments!=0) %>% pull(day) %>% min)){
    lagged_data$mean_score_lag[i] <- NA
  } else {
    lags <- lagged_data %>% filter(ParticipantID == lagged_data$ParticipantID[i] & day < lagged_data$day[i]) %>% dplyr::summarize(mean_score = mean(mean_score, na.rm = T), sum_score = sum(sum_score, na.rm = T))
    lagged_data$mean_score_lag[i] <- lags %>% pull(mean_score)
  }
}

#augment with survey data
lagged_data <- left_join(lagged_data, sample, by = "ParticipantID") %>% 
  mutate(condition = as.factor(condition))

```

### Estimate Social Feedback Models
```{r}
#basic model
model <- glmer(n_comments ~ mean_score_lag + (1 | ParticipantID), 
               data = lagged_data, 
               family = poisson(link = "log"),
               na.action = na.exclude)

summary(model)
```

```{r}
# More elaborate model
model <- glmer(n_comments ~ mean_score_lag + polinterest + (1 | ParticipantID) + (1 | subreddit), 
               data = lagged_data, 
               family = poisson(link = "log"),
               na.action = na.exclude)
summary(model)

```
### Visualization of social feedback effect
```{r}
coef_est <- fixef(model)["mean_score_lag"]
se_est <- summary(model)$coefficients["mean_score_lag", "Std. Error"]
lower_ci <- coef_est - 1.96 * se_est
upper_ci <- coef_est + 1.96 * se_est

coef_df <- data.frame(term = "Mean Score (Lagged)",estimate = coef_est, lower = lower_ci, upper = upper_ci)

coef_label <- paste0(" = ", round(coef_est, 2),
                     " [", round(lower_ci, 2), ", ", round(upper_ci, 2), "]")

# predicted values across the range of mean_score_lag
predictions <- ggpredict(model, terms = c("mean_score_lag [all]", "polinterest [mean]"),
                         bias_correction = TRUE)

# predicted plot
feedback_plot <- ggplot(predictions, aes(x = x, y = predicted)) +
  geom_line(color = "black", size = 0.8) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2, fill = "#6699FF") +
  #annotate("text",x = 0, y = 4, size = 4, hjust = 0,
  #         label = bquote(beta == .(round(coef_est, 2)) ~ "[" ~ .(round(lower_ci, 2)) ~ "," ~ .(round(upper_ci, 2)) ~ "]")) +
  labs(x = "Mean score received on previous comments (lagged)",
       y = "Predicted Number of Comments",
       title = "") +
  theme_bw()+
  theme(axis.title.x = element_text(size = 10),
        axis.title.y = element_text(size = 10))

feedback_plot

ggsave("../output/social_feedback.pdf", feedback_plot, width = 4, height = 3)


# coefficient plot
coef_plot <- ggplot(coef_df, aes(x = term, y = estimate)) +
  geom_point(size = 4, color = "black") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0, color = "black") +
  labs(x = "",
       y = "Effect on Number of Comments \n GLMM Coefficient Estimate, 95%CI",
       title = "Social Feedback") +
  ylim(c(-0.1,0.2))+
  theme_bw()+
  theme(axis.title.y = element_text(size = 10),
        axis.text.x = element_text(size = 10, color = "black"),
        plot.title = element_text(size = 12))

coef_plot

ggsave("../output/social_feedback_coef.pdf", coef_plot, width = 2, height = 4)

feedback_combi <- grid.arrange(coef_plot,feedback_plot, nrow = 1, widths = c(2,4))
ggsave("../output/social_feedback_combi.pdf", feedback_combi, width = 6, height = 3)

```


# Modeling Drop-out with Survival Models
```{r}
# observation period's end (e.g., 30 days after start)
end_of_observation <- as.Date(min(discussion_data$created_comment)) + 30

# Prepare the survival data
survival_data <- discussion_data %>%
  group_by(ParticipantID) %>%
  summarize(discussion_start = min(created_comment),
    last_comment_date = max(created_comment),
    time = as.numeric(pmin(last_comment_date, end_of_observation) - discussion_start),
    status = ifelse(last_comment_date <= end_of_observation, 1, 0))%>%
  left_join(.,scaled_sample,by = "ParticipantID")

# h(t) hazard's function: risk of dying at time t, given the covariates. Covariates > 0 increase in hazard, # covariates < 0 decrease in hazard / negative predictor for dropout.    
res.cox <- coxph(Surv(time,status) ~ condition + group_toxicity, data = survival_data) 
summary(res.cox)
```
## Cox coefficient plot
```{r}
cox_summary <- summary(res.cox)$coefficients

coef_df <- data.frame(term = rownames(cox_summary),
  estimate = cox_summary[, "coef"],
  se = cox_summary[, "se(coef)"]) %>%
  mutate(lower = estimate - 1.96 * se,
         upper = estimate + 1.96 * se)

coef_df <- coef_df %>% 
  filter(term %in% c("conditionincentives", "conditionmoderation", "group_toxicity"))

cox_coef_plot <- ggplot(coef_df, aes(x = estimate, y = term, color = term)) +
  geom_point(size = 4) +
  geom_errorbarh(aes(xmin = lower, xmax = upper), height = 0, size = 1) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  labs(x = "Cox Prop. Hazards Model Coefficient, 95%CIs", 
       title = "Discussion Drop-out", y = "",
       subtitle = "Survival analysis for participation") +
  scale_y_discrete(labels = c("conditionincentives" = "Incentives",
                              "conditionmoderation" = "Moderation",
                              "group_toxicity" = "Group \n Toxicity")) +
  scale_color_manual(values = c(
    "conditionincentives" = "#29c195",
    "conditionmoderation" = "#6699FF",
    "group_toxicity" = "black"
  )) +
  theme_bw()+
  coord_flip()+
  guides(color = "none")

cox_coef_plot
ggsave("../output/cox_coef_plot.pdf", cox_coef_plot, width = 3, height = 4.5)



```


## Kaplan-Meier survival curves for visualization
```{r}
# for different groups
surv_fit <- survfit(Surv(time, status) ~ condition, data = survival_data)

surv_group_plot <- ggsurvplot(surv_fit,
  data = survival_data,
  ggtheme = theme_bw(),
  surv.median.line = "hv",
  pval = TRUE,
  pval.size = 3,
  palette = c("grey","#29c195","#6699FF"), 
  conf.int = TRUE,  
  #risk.table = TRUE,
  #              tables.height = 0.2,
  #              tables.theme = theme_cleantable(),
  legend.title = "Condition", 
  legend.labs = c("Control", "Incentives", "Moderation"), 
  xlab = "Days of Discussion Phase",  
  xlim = c(1, 28) ,
  ylab = "Probability for Continued Participation")

surv_group_plot

ggexport(plotlist =list(surv_group_plot),filename = "../output/group_survival.pdf", width = 4, height = 4)
```


```{r}
# split along toxicity
toxicity_threshold <- quantile(survival_data$group_toxicity, 0.8, na.rm = TRUE)

survival_data <- survival_data %>%
  mutate(toxicity_group = ifelse(group_toxicity > toxicity_threshold, "High", "Low"))

surv_fit <- survfit(Surv(time, status) ~ toxicity_group, data = survival_data)

surv_tox_plot <- ggsurvplot(surv_fit,
  data = survival_data,
  ggtheme = theme_bw(),
  surv.median.line = "hv",
  pval = TRUE,
  pval.size = 3,
  palette = c("black","grey"), 
  conf.int = TRUE,   
  legend.title = "Group Toxicity", # Customize legend title
  legend.labs = c("High", "Low"), 
  xlab = "Days of Discussion Phase",  
  xlim = c(1, 28) ,
  ylab = "Probability for Continued Participation")

surv_tox_plot

ggexport(plotlist = list(surv_tox_plot), filename = "../output/tox_survival.pdf", width = 4, height = 4)
```


